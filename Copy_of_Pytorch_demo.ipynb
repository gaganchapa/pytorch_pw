{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gaganchapa/pytorch_pw/blob/main/Copy_of_Pytorch_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCvlYUCRkfMa"
      },
      "source": [
        "# PyTorch Basics: Tensors & Gradients\n",
        "\n",
        "<img src=\"data:image/png;base64,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\" width=\"600\"\n",
        "     height=\"300\">\n",
        "\n",
        "\n",
        "\n",
        "  PyTorch is an open-source machine learning framework that is primarily used for developing and training deep learning models. It was developed by Facebook's AI Research Lab and released in 2016. PyTorch provides a flexible and dynamic approach to building neural networks, making it a popular choice among researchers and developers.\n",
        "\n",
        "The framework is built on a dynamic computational graph concept, which means that the graph is built and modified on-the-fly as the program runs. This allows for more intuitive and flexible model development, as you can use standard Python control flow statements and debug the model easily.\n",
        "\n",
        "PyTorch supports automatic differentiation, which enables efficient computation of gradients for training neural networks using backpropagation. It provides a rich set of tools and libraries for tasks such as data loading, model building, optimization, and evaluation.\n",
        "\n",
        "One of the key advantages of PyTorch is its support for GPU acceleration, allowing you to train models on GPUs to significantly speed up computations. It also has a large and active community, which means there are plenty of resources, tutorials, and pre-trained models available.\n",
        "\n",
        "PyTorch is often compared to TensorFlow, another popular deep learning framework. While TensorFlow focuses more on static computation graphs, PyTorch emphasizes dynamic computation graphs. This fundamental difference in design philosophy gives PyTorch an edge when it comes to flexibility and ease of use.\n",
        "\n",
        "Overall, PyTorch is widely used in the research community and is gaining popularity in industry applications as well. It provides a powerful and user-friendly platform for building and training deep learning models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5zufMMCkfMo"
      },
      "source": [
        "## installation\n",
        "\n",
        "installation instructions here: https://pytorch.org ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmnQZPSxkfMp"
      },
      "outputs": [],
      "source": [
        "# Uncomment and run the appropriate command for your operating system, if required\n",
        "\n",
        "# Linux / Binder\n",
        "# !pip install numpy torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# Windows\n",
        "# !pip install numpy torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# MacOS\n",
        "# !pip install numpy torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P18JcOiokfMr"
      },
      "source": [
        "Let's import the `torch` module to get started."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGo8nxo7kfMs"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqVgPkfKkfMt"
      },
      "source": [
        "## Tensors\n",
        "\n",
        "At its core, PyTorch is a library for processing tensors. A tensor is a number, vector, matrix, or any n-dimensional array. Let's create a tensor with a single number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUtf5elpkfMv",
        "outputId": "c5065061-a2c3-4868-9091-14e94a619de6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Number\n",
        "t1 = torch.tensor(4.)\n",
        "t1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIB1GJlakfMw"
      },
      "source": [
        "`4.` is a shorthand for `4.0`. It is used to indicate to Python (and PyTorch) that you want to create a floating-point number. We can verify this by checking the `dtype` attribute of our tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jz-QWm7NkfMx",
        "outputId": "9c2aa985-3b39-4feb-941c-d17217d406f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "t1.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd_-gGY-kfMy"
      },
      "source": [
        "Let's try creating more complex tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIn2pRzLkfMz",
        "outputId": "112bf82e-eb1d-4890-ec0c-19145ab98130",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4.])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Vector\n",
        "t2 = torch.tensor([1., 2, 3, 4])\n",
        "t2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdQsBZqukfM0",
        "outputId": "16038d2e-ae5a-4bcd-d8f8-eaa03b69727d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.,  6.],\n",
              "        [ 7.,  8.],\n",
              "        [ 9., 10.]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Matrix\n",
        "t3 = torch.tensor([[5., 6],\n",
        "                   [7, 8],\n",
        "                   [9, 10]])\n",
        "t3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yZHb2E5kfM0",
        "outputId": "a8c5fa5f-2252-4020-9340-da66aaf56cad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[11., 12., 13.],\n",
              "         [13., 14., 15.]],\n",
              "\n",
              "        [[15., 16., 17.],\n",
              "         [17., 18., 19.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# 3-dimensional array\n",
        "t4 = torch.tensor([\n",
        "    [[11, 12, 13],\n",
        "     [13, 14, 15]],\n",
        "    [[15, 16, 17],\n",
        "     [17, 18, 19.]]])\n",
        "t4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS8_bliOkfM1"
      },
      "source": [
        "Tensors can have any number of dimensions and different lengths along each dimension. We can inspect the length along each dimension using the `.shape` property of a tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUx8_FbXkfM1",
        "outputId": "ffa0c7b5-f837-4ce3-efb6-8bdf46ffddd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "print(t1)\n",
        "t1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeRzfymnkfM2",
        "outputId": "f865fea6-cc06-47d0-ecdc-64aaf0eab182",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3., 4.])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "print(t2)\n",
        "t2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXvIYzuxkfM2",
        "outputId": "b0a666fa-4722-4388-804a-446d0899bd68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 5.,  6.],\n",
            "        [ 7.,  8.],\n",
            "        [ 9., 10.]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "print(t3)\n",
        "t3.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5okplTtkfM3",
        "outputId": "83a9b44f-5565-4ae9-be22-b6b625df0080",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[11., 12., 13.],\n",
            "         [13., 14., 15.]],\n",
            "\n",
            "        [[15., 16., 17.],\n",
            "         [17., 18., 19.]]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "print(t4)\n",
        "t4.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NOD0XtokfM3"
      },
      "source": [
        "Note that it's not possible to create tensors with an improper shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiaIlFtWkfM4"
      },
      "outputs": [],
      "source": [
        "# Matrix\n",
        "# t5 = torch.tensor([[5., 6, 11],\n",
        "#                    [7, 8],\n",
        "#                    [9, 10]])\n",
        "# t5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWBdhA9kkfM4"
      },
      "source": [
        "A `ValueError` is thrown because the lengths of the rows `[5., 6, 11]` and `[7, 8]` don't match."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7cKJKdakfM5"
      },
      "source": [
        "## Tensor operations and gradients\n",
        "\n",
        "We can combine tensors with the usual arithmetic operations. Let's look at an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lj6TfIlokfM5",
        "outputId": "8d14760b-6f90-4a86-fe0a-6c113b13b079",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(3.), tensor(4., requires_grad=True), tensor(5., requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "# Create tensors.\n",
        "x = torch.tensor(3.)\n",
        "w = torch.tensor(4., requires_grad=True)\n",
        "b = torch.tensor(5., requires_grad=True)\n",
        "x, w, b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVZlcATrkfM5"
      },
      "source": [
        "We've created three tensors: `x`, `w`, and `b`, all numbers. `w` and `b` have an additional parameter `requires_grad` set to `True`. We'll see what it does in just a moment.\n",
        "\n",
        "Let's create a new tensor `y` by combining these tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKcsAaE0kfM6",
        "outputId": "3d4338d2-9cc8-4855-b66a-2190e647c718",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(17., grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "# # Arithmetic operations\n",
        "y = w * x + b\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNV4U0-OkfM6"
      },
      "source": [
        "As expected, `y` is a tensor with the value `3 * 4 + 5 = 17`. What makes PyTorch unique is that we can automatically compute the derivative of `y` w.r.t. the tensors that have `requires_grad` set to `True` i.e. w and b. This feature of PyTorch is called _autograd_ (automatic gradients).\n",
        "\n",
        "To compute the derivatives, we can invoke the `.backward` method on our result `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RVH2vHCkfM6"
      },
      "outputs": [],
      "source": [
        "# Compute derivatives\n",
        "y.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHyHerbekfM7"
      },
      "source": [
        "The derivatives of `y` with respect to the input tensors are stored in the `.grad` property of the respective tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zTB-VUqkfM7",
        "outputId": "9b253c4b-617b-414b-8fe6-b4f5e490f716",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dy/dx: None\n",
            "dy/dw: tensor(3.)\n",
            "dy/db: tensor(1.)\n"
          ]
        }
      ],
      "source": [
        "# Display gradients\n",
        "print('dy/dx:', x.grad)\n",
        "print('dy/dw:', w.grad)\n",
        "print('dy/db:', b.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvGfw6PJkfM7"
      },
      "source": [
        "As expected, `dy/dw` has the same value as `x`, i.e., `3`, and `dy/db` has the value `1`. Note that `x.grad` is `None` because `x` doesn't have `requires_grad` set to `True`.\n",
        "\n",
        "The \"grad\" in `w.grad` is short for _gradient_, which is another term for derivative. The term _gradient_ is primarily used while dealing with vectors and matrices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvR-LWzgkfM8"
      },
      "source": [
        "## Tensor functions\n",
        "\n",
        "Apart from arithmetic operations, the `torch` module also contains many functions for creating and manipulating tensors. Let's look at some examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gi5eISBckfM8",
        "outputId": "cd6318a2-b551-4147-e25a-09bf7b6c0595",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[42, 42],\n",
              "        [42, 42],\n",
              "        [42, 42]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Create a tensor with a fixed value for every element\n",
        "t6 = torch.full((3, 2), 42)\n",
        "t6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caAPy-P7kfM8",
        "outputId": "b027338b-7253-4a6f-b53d-706b29c083e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.,  6.],\n",
              "        [ 7.,  8.],\n",
              "        [ 9., 10.],\n",
              "        [42., 42.],\n",
              "        [42., 42.],\n",
              "        [42., 42.]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# Concatenate two tensors with compatible shapes\n",
        "t7 = torch.cat((t3, t6))\n",
        "t7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHmUkGOHkfM9",
        "outputId": "3becf85c-b1de-44a3-ef18-01e8678a655c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9589, -0.2794],\n",
              "        [ 0.6570,  0.9894],\n",
              "        [ 0.4121, -0.5440],\n",
              "        [-0.9165, -0.9165],\n",
              "        [-0.9165, -0.9165],\n",
              "        [-0.9165, -0.9165]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# Compute the sin of each element\n",
        "t8 = torch.sin(t7)\n",
        "t8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9UFIgc-kfM9",
        "outputId": "78494ea0-17bb-478f-e677-6cc3680fdfa4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.9589, -0.2794],\n",
              "         [ 0.6570,  0.9894]],\n",
              "\n",
              "        [[ 0.4121, -0.5440],\n",
              "         [-0.9165, -0.9165]],\n",
              "\n",
              "        [[-0.9165, -0.9165],\n",
              "         [-0.9165, -0.9165]]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "# Change the shape of a tensor\n",
        "t9 = t8.reshape(3, 2, 2)\n",
        "t9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YK9aNsnkfM9"
      },
      "source": [
        "You can learn more about tensor operations here: https://pytorch.org/docs/stable/torch.html . Experiment with some more tensor functions and operations using the empty cells below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTgXrNyRkfM-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36942dZpkfM-"
      },
      "source": [
        "## Interoperability with Numpy\n",
        "\n",
        "[Numpy](http://www.numpy.org/) is a popular open-source library used for mathematical and scientific computing in Python. It enables efficient operations on large multi-dimensional arrays and has a vast ecosystem of supporting libraries, including:\n",
        "\n",
        "* [Pandas](https://pandas.pydata.org/) for file I/O and data analysis\n",
        "* [Matplotlib](https://matplotlib.org/) for plotting and visualization\n",
        "* [OpenCV](https://opencv.org/) for image and video processing\n",
        "\n",
        "\n",
        "Instead of reinventing the wheel, PyTorch interoperates well with Numpy to leverage its existing ecosystem of tools and libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKH8QMxDkfM-"
      },
      "source": [
        "Here's how we create an array in Numpy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlCWcXUckfM_",
        "outputId": "7e758367-efd6-4f08-be65-ae631f8a4560",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 2.],\n",
              "       [3., 4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array([[1, 2], [3, 4.]])\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V-UeD40kfM_"
      },
      "source": [
        "We can convert a Numpy array to a PyTorch tensor using `torch.from_numpy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaPUjIiokfNB",
        "outputId": "a652babe-bae8-4c96-c415-7aeee3482f5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# Convert the numpy array to a torch tensor.\n",
        "y = torch.from_numpy(x)\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-kN6vp4kfNC"
      },
      "source": [
        "Let's verify that the numpy array and torch tensor have similar data types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KL76Ma8ekfND",
        "outputId": "0bb945a7-f578-4028-dd79-956e9b1d5bfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dtype('float64'), torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "x.dtype, y.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-vuHKXXkfNE"
      },
      "source": [
        "We can convert a PyTorch tensor to a Numpy array using the `.numpy` method of a tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEBugCySkfNE",
        "outputId": "18673eb2-ae15-4afe-a76c-668c54524cad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 2.],\n",
              "       [3., 4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# Convert a torch tensor to a numpy array\n",
        "z = y.numpy()\n",
        "z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgxySGeWkfNE"
      },
      "source": [
        "The interoperability between PyTorch and Numpy is essential because most datasets you'll work with will likely be read and preprocessed as Numpy arrays.\n",
        "\n",
        "You might wonder why we need a library like PyTorch at all since Numpy already provides data structures and utilities for working with multi-dimensional numeric data. There are two main reasons:\n",
        "\n",
        "1. **Autograd**: The ability to automatically compute gradients for tensor operations is essential for training deep learning models.\n",
        "2. **GPU support**: While working with massive datasets and large models, PyTorch tensor operations can be performed efficiently using a Graphics Processing Unit (GPU). Computations that might typically take hours can be completed within minutes using GPUs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aOg5UDH45k9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear-regression from scrach using pytorch"
      ],
      "metadata": {
        "id": "GPb963Lz5laq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "elamAaJH5tYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#making training data\n",
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70]], dtype='float32')"
      ],
      "metadata": {
        "id": "Ze7LRltk5tUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Targets (apples, oranges)\n",
        "target = np.array([[56, 70],\n",
        "                    [81, 101],\n",
        "                    [119, 133],\n",
        "                    [22, 37],\n",
        "                    [103, 119]], dtype='float32')"
      ],
      "metadata": {
        "id": "ars5xesW5tRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert input and target to tensors\n",
        "inputs = torch.from_numpy(inputs)\n",
        "target = torch.from_numpy(target)\n",
        "\n",
        "print(inputs,\"\\n\")\n",
        "print(target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L92TqO635tPO",
        "outputId": "e40f7801-7da7-4c9e-ceb2-6f0b0f92835f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]]) \n",
            "\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# weights and biases\n",
        "w = torch.randn(2,3 , requires_grad=True)\n",
        "b = torch.randn(2, requires_grad=True)\n",
        "\n",
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-m_2iaph5tMh",
        "outputId": "9f73b09e-29dd-43f9-eb4e-b161e5c570c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2.2317, -1.7551, -0.4958],\n",
            "        [-0.6745, -0.1290,  0.2165]], requires_grad=True)\n",
            "tensor([ 0.5849, -1.1901], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define the model\n",
        "\n",
        "def model(x):\n",
        "  return x @ w.t() + b"
      ],
      "metadata": {
        "id": "ZHqEIQKU56cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction\n",
        "preds = model(inputs)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9J__d3l56Ze",
        "outputId": "889083a3-62c0-4e10-d60a-40ce7f25cd67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 24.5936, -49.7611],\n",
            "        [ 17.4974, -60.0642],\n",
            "        [-69.1874, -64.5976],\n",
            "        [134.4089, -67.5260],\n",
            "        [-48.6152, -44.9575]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#actual\n",
        "print(target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eV0XrG2k56Xf",
        "outputId": "92a59dc7-040e-496a-8434-100055ae59c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function MSE\n",
        "def MSE(actual, target):\n",
        "  diff = actual - target\n",
        "  return torch.sum(diff * diff) / diff.numel()"
      ],
      "metadata": {
        "id": "vlr1NKsC56Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# error\n",
        "loss = MSE(target, preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQJRKGXP56RJ",
        "outputId": "29261703-7533-4c37-bca6-ad09d3acab9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(11745.1895, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute gradients\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "iGypGOsF56Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w, \"\\n\")\n",
        "print(w.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKRT4IVP56Lu",
        "outputId": "7488b6cc-f5eb-432b-ae1e-86a43c16ead1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.9952, -0.2904,  0.6470],\n",
            "        [-0.4967,  0.7654,  1.1847]], requires_grad=True) \n",
            "\n",
            "tensor([[-12572.9834, -13791.0088,  -8395.8984],\n",
            "        [  -268.6556,   -161.0315,    -96.2437]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(b, \"\\n\")\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWMcsxjz6IBr",
        "outputId": "e0357455-9671-4564-c3da-0cc8b28e3ce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3964, 1.3038], requires_grad=True) \n",
            "\n",
            "tensor([-149.4638,   -2.6447])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reset grad\n",
        "w.grad.zero_()\n",
        "b.grad.zero_()\n",
        "\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjdeYBsU6H-6",
        "outputId": "34df0cb4-c1c7-408c-d9d8-349e473301c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adjust params\n",
        "\n",
        "preds = model(inputs)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIbBPr-x6H8l",
        "outputId": "35b3faf3-7cf2-4623-ac7f-0a3289f3563c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-63.8920,  67.2743],\n",
            "        [-74.3183,  99.2876],\n",
            "        [-87.5791, 129.3766],\n",
            "        [-89.6637,  27.3918],\n",
            "        [-50.8660, 123.4462]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss\n",
        "loss = MSE(target, preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEOGA0cy6PzN",
        "outputId": "16ac3312-f4ff-47c6-b1da-06e09f92ba4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(11745.1895, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "\n",
        "print(w.grad, \"\\n\")\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Du5TIt2e6Pwg",
        "outputId": "c9c1531c-8bd7-4dd9-f0bc-2a6b966170ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-12572.9834, -13791.0088,  -8395.8984],\n",
            "        [  -268.6556,   -161.0315,    -96.2437]]) \n",
            "\n",
            "tensor([-149.4638,   -2.6447])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # adjust weight & reset grad\n",
        "with torch.no_grad():\n",
        "    w -= w.grad * 1e-5\n",
        "    b -= b.grad * 1e-5\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()"
      ],
      "metadata": {
        "id": "Jx0SBLV56PtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tD2CAdtn6Pq2",
        "outputId": "5e7717c8-5bf7-42ad-c5a1-425e1e0248d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.8695, -0.1525,  0.7309],\n",
            "        [-0.4940,  0.7671,  1.1857]], requires_grad=True)\n",
            "tensor([0.3979, 1.3038], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate again\n",
        "preds = model(inputs)\n",
        "loss = MSE(target, preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZT-GtGY6Xzq",
        "outputId": "0eaa02f7-e478-43bf-83a5-03725f48e2a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(7931.3271, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training for multiple epochs\n",
        "for i in range(400):\n",
        "  preds = model(inputs)\n",
        "  loss = MSE(target, preds)\n",
        "  loss.backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "     w -= w.grad * 1e-5 # learning rate\n",
        "     b -= b.grad * 1e-5\n",
        "     w.grad.zero_()\n",
        "     b.grad.zero_()\n",
        "  print(f\"Epochs({i}/{400}) & Loss {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijRMFN3C6Xv1",
        "outputId": "39c69394-8d46-4ac3-fc00-c6d7f8a30ed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs(0/100) & Loss 7931.3271484375\n",
            "Epochs(1/100) & Loss 5361.0732421875\n",
            "Epochs(2/100) & Loss 3628.86865234375\n",
            "Epochs(3/100) & Loss 2461.416259765625\n",
            "Epochs(4/100) & Loss 1674.543701171875\n",
            "Epochs(5/100) & Loss 1144.1395263671875\n",
            "Epochs(6/100) & Loss 786.5679321289062\n",
            "Epochs(7/100) & Loss 545.4673461914062\n",
            "Epochs(8/100) & Loss 382.8564147949219\n",
            "Epochs(9/100) & Loss 273.14007568359375\n",
            "Epochs(10/100) & Loss 199.07041931152344\n",
            "Epochs(11/100) & Loss 149.02413940429688\n",
            "Epochs(12/100) & Loss 115.16828918457031\n",
            "Epochs(13/100) & Loss 92.22455596923828\n",
            "Epochs(14/100) & Loss 76.6358871459961\n",
            "Epochs(15/100) & Loss 66.00515747070312\n",
            "Epochs(16/100) & Loss 58.717063903808594\n",
            "Epochs(17/100) & Loss 53.68288040161133\n",
            "Epochs(18/100) & Loss 50.16911697387695\n",
            "Epochs(19/100) & Loss 47.68133544921875\n",
            "Epochs(20/100) & Loss 45.8863410949707\n",
            "Epochs(21/100) & Loss 44.559635162353516\n",
            "Epochs(22/100) & Loss 43.549861907958984\n",
            "Epochs(23/100) & Loss 42.7550163269043\n",
            "Epochs(24/100) & Loss 42.10635757446289\n",
            "Epochs(25/100) & Loss 41.557579040527344\n",
            "Epochs(26/100) & Loss 41.07735061645508\n",
            "Epochs(27/100) & Loss 40.6446533203125\n",
            "Epochs(28/100) & Loss 40.24525451660156\n",
            "Epochs(29/100) & Loss 39.869571685791016\n",
            "Epochs(30/100) & Loss 39.51107406616211\n",
            "Epochs(31/100) & Loss 39.165435791015625\n",
            "Epochs(32/100) & Loss 38.82965850830078\n",
            "Epochs(33/100) & Loss 38.50168991088867\n",
            "Epochs(34/100) & Loss 38.18024444580078\n",
            "Epochs(35/100) & Loss 37.864280700683594\n",
            "Epochs(36/100) & Loss 37.55324172973633\n",
            "Epochs(37/100) & Loss 37.24663543701172\n",
            "Epochs(38/100) & Loss 36.94408416748047\n",
            "Epochs(39/100) & Loss 36.64545440673828\n",
            "Epochs(40/100) & Loss 36.350547790527344\n",
            "Epochs(41/100) & Loss 36.05925750732422\n",
            "Epochs(42/100) & Loss 35.77139663696289\n",
            "Epochs(43/100) & Loss 35.486968994140625\n",
            "Epochs(44/100) & Loss 35.20588684082031\n",
            "Epochs(45/100) & Loss 34.928104400634766\n",
            "Epochs(46/100) & Loss 34.653526306152344\n",
            "Epochs(47/100) & Loss 34.38215255737305\n",
            "Epochs(48/100) & Loss 34.113914489746094\n",
            "Epochs(49/100) & Loss 33.848777770996094\n",
            "Epochs(50/100) & Loss 33.58671188354492\n",
            "Epochs(51/100) & Loss 33.32763671875\n",
            "Epochs(52/100) & Loss 33.0715446472168\n",
            "Epochs(53/100) & Loss 32.818397521972656\n",
            "Epochs(54/100) & Loss 32.568153381347656\n",
            "Epochs(55/100) & Loss 32.32079315185547\n",
            "Epochs(56/100) & Loss 32.07624053955078\n",
            "Epochs(57/100) & Loss 31.834491729736328\n",
            "Epochs(58/100) & Loss 31.59547996520996\n",
            "Epochs(59/100) & Loss 31.359249114990234\n",
            "Epochs(60/100) & Loss 31.125667572021484\n",
            "Epochs(61/100) & Loss 30.89473533630371\n",
            "Epochs(62/100) & Loss 30.66646957397461\n",
            "Epochs(63/100) & Loss 30.4407958984375\n",
            "Epochs(64/100) & Loss 30.21767234802246\n",
            "Epochs(65/100) & Loss 29.997055053710938\n",
            "Epochs(66/100) & Loss 29.778961181640625\n",
            "Epochs(67/100) & Loss 29.563323974609375\n",
            "Epochs(68/100) & Loss 29.350122451782227\n",
            "Epochs(69/100) & Loss 29.13934326171875\n",
            "Epochs(70/100) & Loss 28.930919647216797\n",
            "Epochs(71/100) & Loss 28.724843978881836\n",
            "Epochs(72/100) & Loss 28.521108627319336\n",
            "Epochs(73/100) & Loss 28.319652557373047\n",
            "Epochs(74/100) & Loss 28.120447158813477\n",
            "Epochs(75/100) & Loss 27.9234676361084\n",
            "Epochs(76/100) & Loss 27.728723526000977\n",
            "Epochs(77/100) & Loss 27.536142349243164\n",
            "Epochs(78/100) & Loss 27.345714569091797\n",
            "Epochs(79/100) & Loss 27.15740966796875\n",
            "Epochs(80/100) & Loss 26.971176147460938\n",
            "Epochs(81/100) & Loss 26.787063598632812\n",
            "Epochs(82/100) & Loss 26.6049747467041\n",
            "Epochs(83/100) & Loss 26.424884796142578\n",
            "Epochs(84/100) & Loss 26.2468204498291\n",
            "Epochs(85/100) & Loss 26.07071304321289\n",
            "Epochs(86/100) & Loss 25.896554946899414\n",
            "Epochs(87/100) & Loss 25.72433090209961\n",
            "Epochs(88/100) & Loss 25.553977966308594\n",
            "Epochs(89/100) & Loss 25.38553237915039\n",
            "Epochs(90/100) & Loss 25.21893310546875\n",
            "Epochs(91/100) & Loss 25.05415153503418\n",
            "Epochs(92/100) & Loss 24.891170501708984\n",
            "Epochs(93/100) & Loss 24.72999382019043\n",
            "Epochs(94/100) & Loss 24.570581436157227\n",
            "Epochs(95/100) & Loss 24.412864685058594\n",
            "Epochs(96/100) & Loss 24.256929397583008\n",
            "Epochs(97/100) & Loss 24.102657318115234\n",
            "Epochs(98/100) & Loss 23.95006561279297\n",
            "Epochs(99/100) & Loss 23.799144744873047\n",
            "Epochs(100/100) & Loss 23.649831771850586\n",
            "Epochs(101/100) & Loss 23.502172470092773\n",
            "Epochs(102/100) & Loss 23.356077194213867\n",
            "Epochs(103/100) & Loss 23.21158790588379\n",
            "Epochs(104/100) & Loss 23.06862449645996\n",
            "Epochs(105/100) & Loss 22.927227020263672\n",
            "Epochs(106/100) & Loss 22.78731918334961\n",
            "Epochs(107/100) & Loss 22.64893913269043\n",
            "Epochs(108/100) & Loss 22.51205062866211\n",
            "Epochs(109/100) & Loss 22.376577377319336\n",
            "Epochs(110/100) & Loss 22.242582321166992\n",
            "Epochs(111/100) & Loss 22.110004425048828\n",
            "Epochs(112/100) & Loss 21.97884178161621\n",
            "Epochs(113/100) & Loss 21.849063873291016\n",
            "Epochs(114/100) & Loss 21.720699310302734\n",
            "Epochs(115/100) & Loss 21.593647003173828\n",
            "Epochs(116/100) & Loss 21.467952728271484\n",
            "Epochs(117/100) & Loss 21.343585968017578\n",
            "Epochs(118/100) & Loss 21.220523834228516\n",
            "Epochs(119/100) & Loss 21.09879493713379\n",
            "Epochs(120/100) & Loss 20.978303909301758\n",
            "Epochs(121/100) & Loss 20.859058380126953\n",
            "Epochs(122/100) & Loss 20.741100311279297\n",
            "Epochs(123/100) & Loss 20.624370574951172\n",
            "Epochs(124/100) & Loss 20.50882339477539\n",
            "Epochs(125/100) & Loss 20.39448356628418\n",
            "Epochs(126/100) & Loss 20.28134536743164\n",
            "Epochs(127/100) & Loss 20.169391632080078\n",
            "Epochs(128/100) & Loss 20.058574676513672\n",
            "Epochs(129/100) & Loss 19.94889259338379\n",
            "Epochs(130/100) & Loss 19.84036636352539\n",
            "Epochs(131/100) & Loss 19.732934951782227\n",
            "Epochs(132/100) & Loss 19.62662124633789\n",
            "Epochs(133/100) & Loss 19.521408081054688\n",
            "Epochs(134/100) & Loss 19.41726303100586\n",
            "Epochs(135/100) & Loss 19.314159393310547\n",
            "Epochs(136/100) & Loss 19.212100982666016\n",
            "Epochs(137/100) & Loss 19.11109733581543\n",
            "Epochs(138/100) & Loss 19.011123657226562\n",
            "Epochs(139/100) & Loss 18.91217803955078\n",
            "Epochs(140/100) & Loss 18.814189910888672\n",
            "Epochs(141/100) & Loss 18.717185974121094\n",
            "Epochs(142/100) & Loss 18.62120246887207\n",
            "Epochs(143/100) & Loss 18.526159286499023\n",
            "Epochs(144/100) & Loss 18.432064056396484\n",
            "Epochs(145/100) & Loss 18.338916778564453\n",
            "Epochs(146/100) & Loss 18.246688842773438\n",
            "Epochs(147/100) & Loss 18.155384063720703\n",
            "Epochs(148/100) & Loss 18.064983367919922\n",
            "Epochs(149/100) & Loss 17.97549057006836\n",
            "Epochs(150/100) & Loss 17.88686180114746\n",
            "Epochs(151/100) & Loss 17.799095153808594\n",
            "Epochs(152/100) & Loss 17.712223052978516\n",
            "Epochs(153/100) & Loss 17.62619400024414\n",
            "Epochs(154/100) & Loss 17.541015625\n",
            "Epochs(155/100) & Loss 17.456684112548828\n",
            "Epochs(156/100) & Loss 17.373109817504883\n",
            "Epochs(157/100) & Loss 17.290393829345703\n",
            "Epochs(158/100) & Loss 17.208494186401367\n",
            "Epochs(159/100) & Loss 17.12737464904785\n",
            "Epochs(160/100) & Loss 17.047042846679688\n",
            "Epochs(161/100) & Loss 16.967470169067383\n",
            "Epochs(162/100) & Loss 16.88865089416504\n",
            "Epochs(163/100) & Loss 16.81062889099121\n",
            "Epochs(164/100) & Loss 16.733318328857422\n",
            "Epochs(165/100) & Loss 16.656755447387695\n",
            "Epochs(166/100) & Loss 16.580917358398438\n",
            "Epochs(167/100) & Loss 16.505788803100586\n",
            "Epochs(168/100) & Loss 16.431385040283203\n",
            "Epochs(169/100) & Loss 16.357702255249023\n",
            "Epochs(170/100) & Loss 16.284709930419922\n",
            "Epochs(171/100) & Loss 16.21236228942871\n",
            "Epochs(172/100) & Loss 16.140731811523438\n",
            "Epochs(173/100) & Loss 16.069740295410156\n",
            "Epochs(174/100) & Loss 15.999417304992676\n",
            "Epochs(175/100) & Loss 15.929756164550781\n",
            "Epochs(176/100) & Loss 15.860760688781738\n",
            "Epochs(177/100) & Loss 15.792391777038574\n",
            "Epochs(178/100) & Loss 15.724647521972656\n",
            "Epochs(179/100) & Loss 15.657514572143555\n",
            "Epochs(180/100) & Loss 15.591005325317383\n",
            "Epochs(181/100) & Loss 15.52509593963623\n",
            "Epochs(182/100) & Loss 15.459798812866211\n",
            "Epochs(183/100) & Loss 15.395090103149414\n",
            "Epochs(184/100) & Loss 15.330950736999512\n",
            "Epochs(185/100) & Loss 15.267425537109375\n",
            "Epochs(186/100) & Loss 15.204472541809082\n",
            "Epochs(187/100) & Loss 15.142064094543457\n",
            "Epochs(188/100) & Loss 15.080218315124512\n",
            "Epochs(189/100) & Loss 15.01893138885498\n",
            "Epochs(190/100) & Loss 14.958189010620117\n",
            "Epochs(191/100) & Loss 14.897977828979492\n",
            "Epochs(192/100) & Loss 14.8383150100708\n",
            "Epochs(193/100) & Loss 14.779151916503906\n",
            "Epochs(194/100) & Loss 14.720524787902832\n",
            "Epochs(195/100) & Loss 14.662420272827148\n",
            "Epochs(196/100) & Loss 14.604823112487793\n",
            "Epochs(197/100) & Loss 14.547721862792969\n",
            "Epochs(198/100) & Loss 14.491109848022461\n",
            "Epochs(199/100) & Loss 14.435018539428711\n",
            "Epochs(200/100) & Loss 14.379371643066406\n",
            "Epochs(201/100) & Loss 14.324228286743164\n",
            "Epochs(202/100) & Loss 14.26954460144043\n",
            "Epochs(203/100) & Loss 14.215344429016113\n",
            "Epochs(204/100) & Loss 14.161596298217773\n",
            "Epochs(205/100) & Loss 14.108312606811523\n",
            "Epochs(206/100) & Loss 14.055488586425781\n",
            "Epochs(207/100) & Loss 14.003067016601562\n",
            "Epochs(208/100) & Loss 13.951138496398926\n",
            "Epochs(209/100) & Loss 13.899629592895508\n",
            "Epochs(210/100) & Loss 13.848548889160156\n",
            "Epochs(211/100) & Loss 13.797880172729492\n",
            "Epochs(212/100) & Loss 13.747639656066895\n",
            "Epochs(213/100) & Loss 13.697824478149414\n",
            "Epochs(214/100) & Loss 13.648425102233887\n",
            "Epochs(215/100) & Loss 13.59941291809082\n",
            "Epochs(216/100) & Loss 13.550796508789062\n",
            "Epochs(217/100) & Loss 13.502609252929688\n",
            "Epochs(218/100) & Loss 13.454793930053711\n",
            "Epochs(219/100) & Loss 13.407383918762207\n",
            "Epochs(220/100) & Loss 13.360321044921875\n",
            "Epochs(221/100) & Loss 13.313676834106445\n",
            "Epochs(222/100) & Loss 13.267390251159668\n",
            "Epochs(223/100) & Loss 13.221464157104492\n",
            "Epochs(224/100) & Loss 13.175909042358398\n",
            "Epochs(225/100) & Loss 13.130724906921387\n",
            "Epochs(226/100) & Loss 13.085878372192383\n",
            "Epochs(227/100) & Loss 13.041409492492676\n",
            "Epochs(228/100) & Loss 12.997273445129395\n",
            "Epochs(229/100) & Loss 12.95350456237793\n",
            "Epochs(230/100) & Loss 12.91003704071045\n",
            "Epochs(231/100) & Loss 12.866930961608887\n",
            "Epochs(232/100) & Loss 12.824180603027344\n",
            "Epochs(233/100) & Loss 12.781723976135254\n",
            "Epochs(234/100) & Loss 12.739622116088867\n",
            "Epochs(235/100) & Loss 12.697822570800781\n",
            "Epochs(236/100) & Loss 12.656339645385742\n",
            "Epochs(237/100) & Loss 12.615179061889648\n",
            "Epochs(238/100) & Loss 12.57432746887207\n",
            "Epochs(239/100) & Loss 12.533788681030273\n",
            "Epochs(240/100) & Loss 12.493565559387207\n",
            "Epochs(241/100) & Loss 12.45361042022705\n",
            "Epochs(242/100) & Loss 12.413982391357422\n",
            "Epochs(243/100) & Loss 12.374632835388184\n",
            "Epochs(244/100) & Loss 12.33558177947998\n",
            "Epochs(245/100) & Loss 12.296822547912598\n",
            "Epochs(246/100) & Loss 12.258331298828125\n",
            "Epochs(247/100) & Loss 12.220142364501953\n",
            "Epochs(248/100) & Loss 12.182191848754883\n",
            "Epochs(249/100) & Loss 12.144562721252441\n",
            "Epochs(250/100) & Loss 12.10716438293457\n",
            "Epochs(251/100) & Loss 12.070073127746582\n",
            "Epochs(252/100) & Loss 12.033235549926758\n",
            "Epochs(253/100) & Loss 11.996639251708984\n",
            "Epochs(254/100) & Loss 11.960320472717285\n",
            "Epochs(255/100) & Loss 11.924247741699219\n",
            "Epochs(256/100) & Loss 11.888444900512695\n",
            "Epochs(257/100) & Loss 11.852880477905273\n",
            "Epochs(258/100) & Loss 11.817583084106445\n",
            "Epochs(259/100) & Loss 11.78249454498291\n",
            "Epochs(260/100) & Loss 11.747671127319336\n",
            "Epochs(261/100) & Loss 11.713101387023926\n",
            "Epochs(262/100) & Loss 11.678759574890137\n",
            "Epochs(263/100) & Loss 11.644657135009766\n",
            "Epochs(264/100) & Loss 11.610759735107422\n",
            "Epochs(265/100) & Loss 11.577096939086914\n",
            "Epochs(266/100) & Loss 11.543709754943848\n",
            "Epochs(267/100) & Loss 11.510491371154785\n",
            "Epochs(268/100) & Loss 11.477529525756836\n",
            "Epochs(269/100) & Loss 11.444757461547852\n",
            "Epochs(270/100) & Loss 11.412209510803223\n",
            "Epochs(271/100) & Loss 11.379903793334961\n",
            "Epochs(272/100) & Loss 11.347780227661133\n",
            "Epochs(273/100) & Loss 11.315889358520508\n",
            "Epochs(274/100) & Loss 11.284200668334961\n",
            "Epochs(275/100) & Loss 11.252707481384277\n",
            "Epochs(276/100) & Loss 11.221426963806152\n",
            "Epochs(277/100) & Loss 11.190346717834473\n",
            "Epochs(278/100) & Loss 11.159457206726074\n",
            "Epochs(279/100) & Loss 11.128782272338867\n",
            "Epochs(280/100) & Loss 11.098278999328613\n",
            "Epochs(281/100) & Loss 11.067995071411133\n",
            "Epochs(282/100) & Loss 11.037883758544922\n",
            "Epochs(283/100) & Loss 11.007969856262207\n",
            "Epochs(284/100) & Loss 10.978225708007812\n",
            "Epochs(285/100) & Loss 10.94865894317627\n",
            "Epochs(286/100) & Loss 10.919300079345703\n",
            "Epochs(287/100) & Loss 10.890119552612305\n",
            "Epochs(288/100) & Loss 10.861113548278809\n",
            "Epochs(289/100) & Loss 10.83227252960205\n",
            "Epochs(290/100) & Loss 10.803647994995117\n",
            "Epochs(291/100) & Loss 10.775135040283203\n",
            "Epochs(292/100) & Loss 10.746842384338379\n",
            "Epochs(293/100) & Loss 10.718698501586914\n",
            "Epochs(294/100) & Loss 10.690729141235352\n",
            "Epochs(295/100) & Loss 10.662919998168945\n",
            "Epochs(296/100) & Loss 10.635268211364746\n",
            "Epochs(297/100) & Loss 10.607778549194336\n",
            "Epochs(298/100) & Loss 10.580456733703613\n",
            "Epochs(299/100) & Loss 10.553299903869629\n",
            "Epochs(300/100) & Loss 10.526289939880371\n",
            "Epochs(301/100) & Loss 10.499449729919434\n",
            "Epochs(302/100) & Loss 10.47276496887207\n",
            "Epochs(303/100) & Loss 10.446203231811523\n",
            "Epochs(304/100) & Loss 10.419842720031738\n",
            "Epochs(305/100) & Loss 10.393583297729492\n",
            "Epochs(306/100) & Loss 10.36749267578125\n",
            "Epochs(307/100) & Loss 10.34154224395752\n",
            "Epochs(308/100) & Loss 10.315746307373047\n",
            "Epochs(309/100) & Loss 10.290079116821289\n",
            "Epochs(310/100) & Loss 10.264565467834473\n",
            "Epochs(311/100) & Loss 10.239182472229004\n",
            "Epochs(312/100) & Loss 10.213933944702148\n",
            "Epochs(313/100) & Loss 10.188837051391602\n",
            "Epochs(314/100) & Loss 10.163858413696289\n",
            "Epochs(315/100) & Loss 10.139046669006348\n",
            "Epochs(316/100) & Loss 10.114334106445312\n",
            "Epochs(317/100) & Loss 10.08977222442627\n",
            "Epochs(318/100) & Loss 10.065350532531738\n",
            "Epochs(319/100) & Loss 10.041044235229492\n",
            "Epochs(320/100) & Loss 10.016864776611328\n",
            "Epochs(321/100) & Loss 9.992822647094727\n",
            "Epochs(322/100) & Loss 9.968900680541992\n",
            "Epochs(323/100) & Loss 9.94510269165039\n",
            "Epochs(324/100) & Loss 9.921418190002441\n",
            "Epochs(325/100) & Loss 9.897857666015625\n",
            "Epochs(326/100) & Loss 9.874429702758789\n",
            "Epochs(327/100) & Loss 9.851102828979492\n",
            "Epochs(328/100) & Loss 9.827913284301758\n",
            "Epochs(329/100) & Loss 9.804814338684082\n",
            "Epochs(330/100) & Loss 9.78184700012207\n",
            "Epochs(331/100) & Loss 9.759008407592773\n",
            "Epochs(332/100) & Loss 9.736284255981445\n",
            "Epochs(333/100) & Loss 9.713644027709961\n",
            "Epochs(334/100) & Loss 9.691144943237305\n",
            "Epochs(335/100) & Loss 9.668745040893555\n",
            "Epochs(336/100) & Loss 9.64645767211914\n",
            "Epochs(337/100) & Loss 9.624261856079102\n",
            "Epochs(338/100) & Loss 9.602178573608398\n",
            "Epochs(339/100) & Loss 9.580194473266602\n",
            "Epochs(340/100) & Loss 9.558341026306152\n",
            "Epochs(341/100) & Loss 9.536589622497559\n",
            "Epochs(342/100) & Loss 9.514928817749023\n",
            "Epochs(343/100) & Loss 9.493365287780762\n",
            "Epochs(344/100) & Loss 9.471901893615723\n",
            "Epochs(345/100) & Loss 9.450562477111816\n",
            "Epochs(346/100) & Loss 9.429305076599121\n",
            "Epochs(347/100) & Loss 9.40815544128418\n",
            "Epochs(348/100) & Loss 9.387075424194336\n",
            "Epochs(349/100) & Loss 9.366128921508789\n",
            "Epochs(350/100) & Loss 9.345266342163086\n",
            "Epochs(351/100) & Loss 9.324471473693848\n",
            "Epochs(352/100) & Loss 9.303804397583008\n",
            "Epochs(353/100) & Loss 9.283209800720215\n",
            "Epochs(354/100) & Loss 9.262720108032227\n",
            "Epochs(355/100) & Loss 9.242301940917969\n",
            "Epochs(356/100) & Loss 9.222012519836426\n",
            "Epochs(357/100) & Loss 9.20179557800293\n",
            "Epochs(358/100) & Loss 9.181663513183594\n",
            "Epochs(359/100) & Loss 9.161615371704102\n",
            "Epochs(360/100) & Loss 9.141651153564453\n",
            "Epochs(361/100) & Loss 9.121776580810547\n",
            "Epochs(362/100) & Loss 9.101978302001953\n",
            "Epochs(363/100) & Loss 9.082280158996582\n",
            "Epochs(364/100) & Loss 9.06267261505127\n",
            "Epochs(365/100) & Loss 9.043146133422852\n",
            "Epochs(366/100) & Loss 9.023681640625\n",
            "Epochs(367/100) & Loss 9.004318237304688\n",
            "Epochs(368/100) & Loss 8.985018730163574\n",
            "Epochs(369/100) & Loss 8.965807914733887\n",
            "Epochs(370/100) & Loss 8.946683883666992\n",
            "Epochs(371/100) & Loss 8.927637100219727\n",
            "Epochs(372/100) & Loss 8.908659934997559\n",
            "Epochs(373/100) & Loss 8.889779090881348\n",
            "Epochs(374/100) & Loss 8.870962142944336\n",
            "Epochs(375/100) & Loss 8.852224349975586\n",
            "Epochs(376/100) & Loss 8.833547592163086\n",
            "Epochs(377/100) & Loss 8.814966201782227\n",
            "Epochs(378/100) & Loss 8.796453475952148\n",
            "Epochs(379/100) & Loss 8.778002738952637\n",
            "Epochs(380/100) & Loss 8.75964069366455\n",
            "Epochs(381/100) & Loss 8.74134635925293\n",
            "Epochs(382/100) & Loss 8.723102569580078\n",
            "Epochs(383/100) & Loss 8.70495319366455\n",
            "Epochs(384/100) & Loss 8.686869621276855\n",
            "Epochs(385/100) & Loss 8.668852806091309\n",
            "Epochs(386/100) & Loss 8.650908470153809\n",
            "Epochs(387/100) & Loss 8.633036613464355\n",
            "Epochs(388/100) & Loss 8.615227699279785\n",
            "Epochs(389/100) & Loss 8.597481727600098\n",
            "Epochs(390/100) & Loss 8.579803466796875\n",
            "Epochs(391/100) & Loss 8.56220817565918\n",
            "Epochs(392/100) & Loss 8.54467487335205\n",
            "Epochs(393/100) & Loss 8.527203559875488\n",
            "Epochs(394/100) & Loss 8.509782791137695\n",
            "Epochs(395/100) & Loss 8.492441177368164\n",
            "Epochs(396/100) & Loss 8.475157737731934\n",
            "Epochs(397/100) & Loss 8.457937240600586\n",
            "Epochs(398/100) & Loss 8.440777778625488\n",
            "Epochs(399/100) & Loss 8.42369270324707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(inputs)\n",
        "loss = MSE(target, preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rShT9Hmj6XtR",
        "outputId": "878643f8-7e16-464d-dde4-fec7ebc807ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(8.4067, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt\n",
        "sqrt(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cezq8zGu6Xqs",
        "outputId": "0a1327b1-55e3-4ba0-fa90-2a76cfba3a68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.8994260680430965"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvsKGPfB6XoH",
        "outputId": "7ef9b046-3360-4da0-c68d-410599597c7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 57.1376,  70.2683],\n",
              "        [ 84.6635, 101.9082],\n",
              "        [113.1516, 130.2125],\n",
              "        [ 20.7796,  35.6383],\n",
              "        [106.4495, 122.3522]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U8284MJ6p5w",
        "outputId": "6ad42b9b-c6c6-4228-bc65-c0b0e118c9d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## You can see they are almost close earch other"
      ],
      "metadata": {
        "id": "3jkj32ag6p3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UHrHiAXZ6pzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network using Pytorch"
      ],
      "metadata": {
        "id": "6-OUXNOx3CPg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHo8uHimkfNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b977661-d371-4d4a-f154-88cfdfe6009c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jan  5 18:17:23 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   70C    P0              29W /  70W |    181MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# To check GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "jv4zRj3u3LtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "id": "Swc3R2Ki3OSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(training_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cd71u_LZ3QMo",
        "outputId": "5a3f9c78-5849-4268-f073-7a256606ee03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchvision.datasets.mnist.FashionMNIST"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
        "    print(\"Shape of y: \", y.shape, y.dtype)\n",
        "    # print(X)\n",
        "    # print(y)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_z8xEoct3Taa",
        "outputId": "946fc76c-d47e-4df1-8d33-dfba727b96f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
            "Shape of y:  torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fx_2V-C83aUS",
        "outputId": "5408e3d3-eb6e-478f-bc85-958a5e6b96fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueZJS_-L3VQ4",
        "outputId": "ca714a64-03f5-488c-f511-3d13bf6bbc62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "1SEEk4fz3ey2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "tryz3wtG3ewp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "Z1C_N3if3j-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UxIUc-Y3mSp",
        "outputId": "8718228a-6d04-40c1-ce26-ca7867d1d02a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.300663  [    0/60000]\n",
            "loss: 2.293000  [ 6400/60000]\n",
            "loss: 2.272770  [12800/60000]\n",
            "loss: 2.257069  [19200/60000]\n",
            "loss: 2.241643  [25600/60000]\n",
            "loss: 2.215969  [32000/60000]\n",
            "loss: 2.219614  [38400/60000]\n",
            "loss: 2.192836  [44800/60000]\n",
            "loss: 2.173613  [51200/60000]\n",
            "loss: 2.140145  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 55.1%, Avg loss: 2.141554 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.151614  [    0/60000]\n",
            "loss: 2.141775  [ 6400/60000]\n",
            "loss: 2.082129  [12800/60000]\n",
            "loss: 2.088774  [19200/60000]\n",
            "loss: 2.029911  [25600/60000]\n",
            "loss: 1.977006  [32000/60000]\n",
            "loss: 1.993940  [38400/60000]\n",
            "loss: 1.921719  [44800/60000]\n",
            "loss: 1.918592  [51200/60000]\n",
            "loss: 1.838653  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 57.4%, Avg loss: 1.844318 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.881702  [    0/60000]\n",
            "loss: 1.849864  [ 6400/60000]\n",
            "loss: 1.731845  [12800/60000]\n",
            "loss: 1.765697  [19200/60000]\n",
            "loss: 1.650881  [25600/60000]\n",
            "loss: 1.614644  [32000/60000]\n",
            "loss: 1.630156  [38400/60000]\n",
            "loss: 1.545160  [44800/60000]\n",
            "loss: 1.566212  [51200/60000]\n",
            "loss: 1.455879  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 61.0%, Avg loss: 1.481085 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.552089  [    0/60000]\n",
            "loss: 1.519401  [ 6400/60000]\n",
            "loss: 1.371943  [12800/60000]\n",
            "loss: 1.437813  [19200/60000]\n",
            "loss: 1.317096  [25600/60000]\n",
            "loss: 1.323671  [32000/60000]\n",
            "loss: 1.336043  [38400/60000]\n",
            "loss: 1.273054  [44800/60000]\n",
            "loss: 1.300039  [51200/60000]\n",
            "loss: 1.196054  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 63.3%, Avg loss: 1.229634 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.309162  [    0/60000]\n",
            "loss: 1.294167  [ 6400/60000]\n",
            "loss: 1.130135  [12800/60000]\n",
            "loss: 1.229786  [19200/60000]\n",
            "loss: 1.099931  [25600/60000]\n",
            "loss: 1.133777  [32000/60000]\n",
            "loss: 1.155492  [38400/60000]\n",
            "loss: 1.102494  [44800/60000]\n",
            "loss: 1.131642  [51200/60000]\n",
            "loss: 1.042439  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.9%, Avg loss: 1.072273 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save model\n",
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqdoWByK3oxh",
        "outputId": "a1dcb0a7-515d-4af5-a4ad-1625900ed09c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load model\n",
        "model = NeuralNetwork()\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gB0EWHe24DXZ",
        "outputId": "ef764737-517b-4351-9360-c8a50d598b40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Prediction\n",
        "\n",
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRHA5ZZP4HEJ",
        "outputId": "884163ae-0428-4448-f93e-e60cc52c201c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data\n"
      ],
      "metadata": {
        "id": "7zvhooAy4KUJ",
        "outputId": "5053cb60-470c-4254-81e1-61b8c61519c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ad1smyZO2Oxd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}